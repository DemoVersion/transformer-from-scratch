# PyTorch optim module stub file
from typing import Any, Iterable, Union, Optional, Callable

class Optimizer:
    def __init__(self, params: Iterable[Any]) -> None: ...
    def zero_grad(self) -> None: ...
    def step(self) -> None: ...

class Adam(Optimizer):
    def __init__(self, params: Iterable[Any], lr: float = 0.001, **kwargs: Any) -> None: ...

class lr_scheduler:
    class LambdaLR:
        def __init__(self, optimizer: Optimizer, lr_lambda: Callable[[int], float], **kwargs: Any) -> None: ...
        def step(self) -> None: ...