# Transformers library stub
from typing import Any, Dict, Optional

class GPT2Config:
    n_ctx: int
    def __init__(self, **kwargs: Any) -> None: ...

class GPT2LMHeadModel:
    config: GPT2Config
    def __init__(self, config: GPT2Config) -> None: ...
    def to(self, device: Any) -> "GPT2LMHeadModel": ...
    def cuda(self) -> "GPT2LMHeadModel": ...
    def __call__(self, *args: Any, **kwargs: Any) -> Any: ...
    @classmethod
    def from_pretrained(cls, name: str, **kwargs: Any) -> "GPT2LMHeadModel": ...

class GPT2Tokenizer:
    def __init__(self) -> None: ...
    def __call__(self, text: str, return_tensors: str = "pt") -> Dict[str, Any]: ...
    @classmethod
    def from_pretrained(cls, name: str, **kwargs: Any) -> "GPT2Tokenizer": ...